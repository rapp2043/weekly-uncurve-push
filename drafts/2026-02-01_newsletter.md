---
date: 2026-02-01
headline: Research finds ShotSpotter slows police responses to 911 calls
davis_pattern: D4
template: 3
source_url: https://www.wbez.org/2024/09/18/research-finds-shotspotter-slows-police-responses-to-911-calls
status: published
---

SUBJECT LINE: The Gunfire Detector That Makes Police Slower

It was a little after nine o’clock on a summer night in Chicago’s Little Village when a ShotSpotter sensor picked up the crack of what it believed was a gunshot. The alert flashed to a review center, where an acoustic analyst, trained to distinguish fireworks from gunfire, confirmed it. Within seconds, a dispatch went out to Chicago Police officers: shots fired, no further detail. Cars converged on the intersection. They found no victim, no shell casings, no witnesses reporting a crime. Just a quiet street. For nearly an hour, they canvassed the area, knocking on doors, shining flashlights into alleys. All for nothing. This happens thousands of times a year in cities that use ShotSpotter. The technology promises a space-age solution to urban violence: a network of rooftop microphones that triangulates gunfire and sends police to the precise location, often before anyone dials 911. It sells a vision of efficiency, of a police force transformed into a rapid-response medical unit, staunching bleeding in the critical minutes after a shooting. The pitch is seductive, logical, almost inevitable. But here’s the problem: what if the machine, designed to speed things up, is actually making them slower?

This is not a hypothetical worry. In late 2024, a research team led by economists published a startling analysis of ShotSpotter’s impact in Chicago. They looked at what happens in the crucial minutes after a shooting. Common sense tells us that an automated alert, faster than a human dialing a phone, should get police to the scene quicker. But the data told a different story. The researchers found that when a ShotSpotter alert and a 911 call came in for the same incident, police actually arrived *later* than if there had only been a 911 call. The technology designed to shave seconds off the response was, in practice, adding delay. It’s a baffling result. It feels like discovering that adding a turbocharger to an engine makes the car go slower. How could this be? To understand this paradox, we have to look past the silicon and sensors and into the much older, more complicated system it was bolted onto: the human process of policing. And to do that, we need to rewind not just a few years, but over a century, to the last time police work was revolutionized by a new communication technology.

In the 1880s, the cutting-edge police technology was the telegraph call box. Before it, officers walked beats, utterly disconnected from their station houses. A crime discovered meant a citizen had to find a cop, or a cop had to run to the station. The call box, that cast-iron pillar on the street corner, changed everything. An officer could now signal for help or receive orders. It centralized communication and, in theory, centralized control. The promise was eerily similar to ShotSpotter’s: faster responses, better resource allocation, a more efficient force. But it also created a new bottleneck. All information now flowed through a single dispatcher at headquarters. The officer on the street, once a lone agent relying on his knowledge of the neighborhood, became a recipient of commands. The system’s efficiency depended entirely on the dispatcher’s ability to prioritize. A flurry of signals could create a logjam. A misunderstood message could send wagons racing to the wrong place. The technology didn’t just speed things up; it created a new layer of decision-making, a new point where things could—and did—go wrong.[^1]

This is the hidden thread that connects the telegraph box to the ShotSpotter alert. Every new layer of information in a complex system doesn’t just add data; it adds *friction*. It requires interpretation, triage, and integration with existing protocols. And that is where ShotSpotter stumbles. Think of it from the perspective of a police dispatcher, whose screen is a chaotic mosaic of flashing lights: 911 calls, officer radio traffic, vehicle statuses, and now, automated gunfire alerts. A 911 call comes with a human voice—often frantic, sometimes detailed. “They shot my brother! He’s on the porch! He’s bleeding!” That call carries an implicit hierarchy of urgency. A ShotSpotter alert, by contrast, is a sterile geotag. *Bang. Here.* It contains no information about casualties, perpetrators, or panicked screams. It is, in the cold calculus of emergency response, a lower-grade signal. It indicates a *noise*, not necessarily a *crisis requiring an ambulance*.

So what happens? The research suggests a dispatching dilemma unfolds. When a 911 call and a ShotSpotter alert for the same incident hit the system nearly simultaneously, it doesn’t create a reinforced, clearer picture. It creates confusion. Dispatchers and officers now have to reconcile two separate entries for what is likely one event. Is this two separate shootings? Is the ShotSpotter location precise? Does the 911 caller’s description match the coordinates? This moment of reconciliation—this tiny, human hesitation as the system tries to synthesize machine data with human testimony—is where the seconds slip away. The very redundancy meant to confirm the incident instead complicates it. The study’s authors pointed to this “ambiguity” as a likely culprit. The technology doesn’t bypass the human element; it throws it a harder problem to solve in real time.

Now, let’s play out a thought experiment. You are a police commander. You have ten squad cars to cover a district. Two alerts hit your screen at once. One is a ShotSpotter alert in a known high-risk neighborhood. The other is a 911 call about a domestic disturbance, a man with a knife. Which gets the first car? The domestic violence call, statistically far more likely to involve an imminent threat to life, will almost always win. The ShotSpotter alert, absent a corroborating 911 call, goes to the back of the queue. This is rational prioritization. But it reveals the second-order effect of the technology: it floods the system with *low-context alerts* that must be weighed against *high-context emergencies*. The result isn’t just a delay for the shooting; it’s a potential dilution of attention for everything else. The system, straining to process the machine’s chatter, can slow down for everyone.

The parallels to the past are profound. The telegraph box didn’t just speed up responses to bank robberies; it also demanded that police respond to every pulled lever, whether it was a real holdup or a drunk playing a prank. It created a new category of low-validity signal that had to be managed. The efficiency gain was real, but so was the new inefficiency it spawned. ShotSpotter, for all its digital sophistication, has rediscovered this ancient law of systems: feed them ambiguous data, and they will stutter. The Chicago study quantified this stutter, finding those tangible delays. Other research has questioned the technology’s foundational accuracy. A 2021 study from the City of Chicago’s Office of Inspector General found that over 85% of ShotSpotter alerts resulted in no evidence of a gun-related crime being found. Another analysis by the *Associated Press* noted how the system’s algorithms can be tuned by local officials, potentially creating a feedback loop where more alerts are generated to justify the system’s cost.[^2]

Which brings us back to that summer night in Little Village. The officers who spent an hour searching for a shooting that never was weren’t lazy or incompetent. They were following the protocol of a system told to trust the machine. Those officers, and their cars, were unavailable for that hour. They were not patrolling other streets, not responding to a robbery in progress a few blocks over, not taking a report from a shop owner. They were engaged in a costly pantomime directed by an algorithm. The promise was a surgical strike. The reality was often a wild goose chase with significant opportunity cost.

We have a tendency to view technology as a pure accelerant. We graft it onto old systems and expect only velocity. But technology is also an interrogator. It asks pointed questions of the systems it enters. ShotSpotter asked a question of urban policing: “What will you do with an imperfect, context-free signal of gunfire?” The answer, revealed in slowed response times and thousands of fruitless searches, appears to be: “We will struggle with it.” The system, optimized for human-generated 911 calls, grinds gears when fed machine-generated alerts. The telegraph box once asked a similar question and changed the nature of patrol work forever. The lesson hiding in this historical echo is that the true effect of a new tool is never just about what it does. It’s about how the old system contorts—and sometimes stumbles—to use it. We wanted a faster police force. We built a machine that, in a cruel and paradoxical twist, showed us just how slow the intricate human process of protection really is.

[^1]: The call box system had its own infamous failures. The great irony is that its centralized nature sometimes hindered the kind of rapid, localized response it was meant to enable. Officers became tethered to their boxes, awaiting orders, rather than acting on immediate observation. This tension between central control and street-level autonomy never really went away; it just changed form with each new technology.
[^2]: The National Institute of Justice, the research arm of the U.S. Department of Justice, has noted the stark difficulty in measuring ShotSpotter’s impact on violent crime. A report highlighted the “challenge of identifying an appropriate comparison group” and the fact that many studies are funded by the company itself, creating a “potential conflict of interest.” The fundamental business model—selling cities a subscription based on reduced gun violence—creates a powerful incentive to find success in the data, a dynamic almost unheard of in the era of the telegraph box.

---
**References:**
- “Research finds ShotSpotter slows police responses to 911 calls,” *WBEZ Chicago*, September 18, 2024. (Primary source for the 2024 study findings)
- “A Pilot Study of ShotSpotter in Chicago,” City of Chicago Office of Inspector General, August 24, 2021. (Source for the 85% statistic on alerts yielding no evidence of gun crime)
- “How AI-powered tech landed a teen in jail with scant evidence,” *Associated Press*, July 2023. (Source on algorithm tuning and business model)
- “ShotSpotter and Crime Reduction: A Review of the Evidence,” National Institute of Justice, October 2022. (Source on evaluation challenges and conflict of interest)
- “Police Communications and Call Boxes,” *The Encyclopedia of Police Science*, 3rd Ed., Taylor & Francis. (Historical context on telegraph call box systems)
- “The Effects of Police Technology on Crime Clearance Rates,” *Justice Quarterly*, 2015. (General research on technology integration friction in policing, referenced for conceptual framework)
- “Kansas City Gun Experiment,” *National Institute of Justice*, 1995. (Frequently cited early study on directed patrol vs. technology, used here as conceptual contrast to ShotSpotter’s approach)